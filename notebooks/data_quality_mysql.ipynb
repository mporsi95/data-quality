{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Spark session\n",
      "SparkSession created at http://matheus:4040\n"
     ]
    }
   ],
   "source": [
    "from dhzlib import DhzLib\n",
    "dhz = DhzLib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8031506\n",
      "root\n",
      " |-- ride_id: string (nullable = true)\n",
      " |-- rideable_type: string (nullable = true)\n",
      " |-- started_at: timestamp (nullable = true)\n",
      " |-- ended_at: timestamp (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- start_lat: float (nullable = true)\n",
      " |-- start_lng: float (nullable = true)\n",
      " |-- end_lat: float (nullable = true)\n",
      " |-- end_lng: float (nullable = true)\n",
      " |-- member_casual: string (nullable = true)\n",
      "\n",
      "None\n",
      "+----------------+-------------+-------------------+-------------------+--------------------------------------------+----------------+-------------------------------------------+--------------+----------------+------------------+---------+----------+-------------+\n",
      "|ride_id         |rideable_type|started_at         |ended_at           |start_station_name                          |start_station_id|end_station_name                           |end_station_id|start_lat       |start_lng         |end_lat  |end_lng   |member_casual|\n",
      "+----------------+-------------+-------------------+-------------------+--------------------------------------------+----------------+-------------------------------------------+--------------+----------------+------------------+---------+----------+-------------+\n",
      "|CB181909FC05004F|electric_bike|2023-10-29 09:10:14|2023-10-29 09:25:19|11th & Clifton St NW                        |31136           |L'Enfant Plaza / 7th & C St SW             |31218         |38.922089219    |-77.027171969     |38.886266|-77.022241|member       |\n",
      "|77832F0C46F1B308|classic_bike |2023-10-28 12:26:17|2023-10-28 12:35:41|11th & Clifton St NW                        |31136           |Massachusetts Ave & Dupont Circle NW       |31200         |38.9223243445331|-77.02708572149277|38.9101  |-77.0444  |member       |\n",
      "|777600C797581E8F|classic_bike |2023-10-01 10:18:50|2023-10-01 10:51:19|12th St & New York Ave NW                   |31670           |Massachusetts Ave & Dupont Circle NW       |31200         |38.901104       |-77.028061        |38.9101  |-77.0444  |casual       |\n",
      "|8A8C4C384180159A|classic_bike |2023-10-05 10:40:56|2023-10-05 11:27:40|36th & Calvert St NW / Glover Park          |31304           |Massachusetts Ave & Dupont Circle NW       |31200         |38.922581       |-77.070334        |38.9101  |-77.0444  |casual       |\n",
      "|C3CD670D215D5202|classic_bike |2023-10-23 18:30:45|2023-10-23 18:43:23|W&OD Trail/Sunset Hills Rd & Isaac Newton Sq|32220           |W&OD Trail & Explorer St/Reston Bus Station|32214         |38.951443       |-77.340377        |38.957037|-77.359718|casual       |\n",
      "+----------------+-------------+-------------------+-------------------+--------------------------------------------+----------------+-------------------------------------------+--------------+----------------+------------------+---------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df = dhz.spark.read.csv('../data/*.csv', header=True, inferSchema=True)\n",
    "tr_df = raw_df.select(\n",
    "    raw_df.ride_id.alias('ride_id'),\n",
    "    raw_df.rideable_type.alias('rideable_type'),\n",
    "    raw_df.started_at.cast('timestamp').alias('started_at'),\n",
    "    raw_df.ended_at.cast('timestamp').alias('ended_at'),\n",
    "    raw_df.start_station_name.alias('start_station_name'),\n",
    "    raw_df.start_station_id.cast('int').alias('start_station_id'),\n",
    "    raw_df.end_station_name.alias('end_station_name'),\n",
    "    raw_df.end_station_id.cast('int').alias('end_station_id'),\n",
    "    raw_df.start_lat.cast('float').alias('start_lat'),\n",
    "    raw_df.start_lng.cast('float').alias('start_lng'),\n",
    "    raw_df.end_lat.cast('float').alias('end_lat'),\n",
    "    raw_df.end_lng.cast('float').alias('end_lng'),\n",
    "    raw_df.member_casual.alias('member_casual')\n",
    ")\n",
    "\n",
    "print(raw_df.count())\n",
    "print(tr_df.printSchema())\n",
    "raw_df.limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes de Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from datetime import date, datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dhzlib' object has no attribute 'check_interval_integrity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lower_bound \u001b[38;5;241m=\u001b[39m date(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m      2\u001b[0m upper_bound \u001b[38;5;241m=\u001b[39m date(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m31\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdhz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_interval_integrity\u001b[49m(tr_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarted_at\u001b[39m\u001b[38;5;124m'\u001b[39m, lower_bound, upper_bound)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dhzlib' object has no attribute 'check_interval_integrity'"
     ]
    }
   ],
   "source": [
    "lower_bound = date(2023, 3, 16)\n",
    "upper_bound = date(2023, 3, 31)\n",
    "dhz.check_interval_integrity(tr_df, 'started_at', lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|started_at|\n",
      "+----------+\n",
      "|2023-03-31|\n",
      "|2023-03-30|\n",
      "|2023-03-29|\n",
      "|2023-03-28|\n",
      "|2023-03-27|\n",
      "|2023-03-26|\n",
      "|2023-03-25|\n",
      "|2023-03-24|\n",
      "|2023-03-23|\n",
      "|2023-03-22|\n",
      "|2023-03-21|\n",
      "|2023-03-20|\n",
      "|2023-03-19|\n",
      "|2023-03-18|\n",
      "|2023-03-17|\n",
      "|2023-03-16|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_df.filter(F.col('started_at').cast('date').between(lower_bound, upper_bound)) \\\n",
    "    .select(F.col('started_at').cast('date')).distinct().orderBy('started_at',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2023, 3, 16),\n",
       " datetime.date(2023, 3, 17),\n",
       " datetime.date(2023, 3, 18),\n",
       " datetime.date(2023, 3, 19),\n",
       " datetime.date(2023, 3, 20),\n",
       " datetime.date(2023, 3, 21),\n",
       " datetime.date(2023, 3, 22),\n",
       " datetime.date(2023, 3, 23),\n",
       " datetime.date(2023, 3, 24),\n",
       " datetime.date(2023, 3, 25),\n",
       " datetime.date(2023, 3, 26),\n",
       " datetime.date(2023, 3, 27),\n",
       " datetime.date(2023, 3, 28),\n",
       " datetime.date(2023, 3, 29),\n",
       " datetime.date(2023, 3, 30),\n",
       " datetime.date(2023, 3, 31)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start=lower_bound,\n",
    "              end=upper_bound,\n",
    "              freq='d').map(lambda x: datetime.date(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = tr_df.filter(F.col('started_at').between(lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2023, 3, 30),\n",
       " datetime.date(2023, 3, 29),\n",
       " datetime.date(2023, 3, 28),\n",
       " datetime.date(2023, 3, 27),\n",
       " datetime.date(2023, 3, 26),\n",
       " datetime.date(2023, 3, 25),\n",
       " datetime.date(2023, 3, 24),\n",
       " datetime.date(2023, 3, 23),\n",
       " datetime.date(2023, 3, 22),\n",
       " datetime.date(2023, 3, 21),\n",
       " datetime.date(2023, 3, 20),\n",
       " datetime.date(2023, 3, 19),\n",
       " datetime.date(2023, 3, 18),\n",
       " datetime.date(2023, 3, 17),\n",
       " datetime.date(2023, 3, 16)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.select(F.col('started_at').cast('date')).distinct().orderBy('started_at', ascending=False).toPandas()['started_at'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = set(filtered_df.select(F.col('started_at').cast('date')).distinct().toPandas()['started_at'].tolist())\n",
    "dict2 = set(pd.date_range(start=lower_bound,\n",
    "              end=upper_bound,\n",
    "              freq='d').map(lambda x: datetime.date(x)).tolist())\n",
    "dict1 == dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2023, 3, 31)}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1.symmetric_difference(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking interval integrity for column started_at\n",
      "Interval: 2023-03-16 to 2023-03-31\n",
      "Integrity check passed for started_at\n"
     ]
    }
   ],
   "source": [
    "check_interval_integrity(1,tr_df, 'started_at', lower_bound, upper_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 3, 31)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = tr_df.filter(F.col('started_at').between(lower_bound, upper_bound))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.select(F.col('started_at').cast('date')).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df.filter(F.col('started_at').between(lower_bound, upper_bound)) \\\n",
    "    .select(F.col('started_at').cast('date')).distinct().count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
